# ARplusR開発メモ

## 工程

- [x] ARマーカーから作られたオブジェクトの座標を取得する(とりあえずTextでリアルタイム表示)
- [x] タップした場所にオブジェクトを生成できるようにする
- [x] オブジェクトにARマーカーが一定以上近づいたらARマーカーオブジェクトの色を変える
- [x] Cubeが直進する用にする
- [x] Cubeが障害物のオブジェクトに近づいたらそれを避けて進むようにする
- [ ] ロボットの実機の様子を見てmicro: bitでBLEするかRaspberry Piを使うかを決める
- [ ] 通信部分を作成
- [ ] 結合テスト
- [ ] 完成

---

## 方向性

  ARマーカーを認識して生成されたオブジェクト(以下仮想ロボットオブジェクト)は最終的には見えないようにする。2020年4月26日わかったことだが、どうやらそれはRendererを無効にすればいいらしい。仮想ロボットオブジェクトのColliderのX, Yの値を大きくし、OnTriggerStayで避ける処理を実行。避けるための動きの方向はUnity上で決定し、それを現実のロボットに配信する形をとる。AR上で現実のラジコンを動かすようなイメージ。

---

## 開発日記

### 2020年4月25日

 工程の最初である**"ARマーカーから作られたオブジェクトの座標を取得する"**はできた。しかし、予想と違って座標は相対的な変化であった。つまり、マーカーを動かすと座標が変化することはもちろんだが,自分自身(AR Camera)が動いても座標が変わった。しかし、結局やりたいことはAR上のオブジェクトとARマーカーを認識して生成されたオブジェクトとの相対的な距離がわかれば良いので、問題はなさそう。ARマーカーの認識が外れるともう一度認識させようとしてもうまく行かないことがほとんどであることがわかった。ARマーカーの認識精度自体は悪くないので、しっかりとカメラで追い続ければ大丈夫だと思われる。

### 2020年4月26日

 姿を消すにはhttps://marunouchi-tech.i-studio.co.jp/2356/によるとRendererをオフにすればいい。なるほど、言われてみればそうだ。仮想ロボットオブジェクトと障害物の接触検知はうまく行かなかった。仮想ロボットオブジェクトはARマーカーを認識すると生成されるオブジェクトで、AR Foundation のAR Tracked Image Managerスクリプトが管理している。Tracked Image PrefabにはCubeを指定している。障害物もほどんど同様のCubeのPrefabで、画面をタップするとAR上で平面と識別された場所に配置される。障害物のIsTriggerをtrueに、仮想ロボットオブジェクトのIsTriggerはfalseのままにして仮想ロボットオブジェクトのOnTriggerStayに

```c#
other.transform.Rotate(new Vector3(15, 30, 45) * Time.deltaTime);
```

としたが動かなかった。Debug.Logに出力することも試したが出力はなかった。OnTriggerEnterに同様にDebug.Logを試したが効果はなかった。(他のシチュエーションでDebug.Logが正常に動くことは確認済み)

### 2020年4月27日

 原因解明に少しずつ近づきつつある。どうやら、2020年4月25日にできたと思われた**"ARマーカーから作られたオブジェクトの座標を取得する"**が実はうまくできていないことがわかった。画面をタップすることで生成されるオブジェクトはカメラの位置を変えても座標が変化しなかった。よく考えてみると、Unityの座標が全てカメラからの相対的な距離として定義されているとは考えにくい。仮想ロボットオブジェクトの座標がカメラからの相対的な位置ならば、カメラの座標と(0, 0, 0)の距離を足せば仮想ロボットオブジェクトの座標を出せるかもしれない。それでも先へ進めそうだが、この先の実装を考えるとできればColliderを使って検知する方法をとりたい。

### 2020年4月28日

*<font color="#FF0461">変更点多量</font>*

 一度強制再起動がかかってUnity上のデータが吹っ飛んだが、改めてやり直したらうまくいった。一定の距離以下になったらそれを検知して障害物がその場で回転させるようにした。デバッグのために一時的に構成を替えてやっている。具体的には、PlaceVirtualRobotなるスクリプトを作成し、ボタンで仮想ロボットを配置できるようにした。これに伴い、"画面をタップしたときに平面を検知していたら障害物を置く"という条件がコンフリクトする用になったので、ARTapToPlaceObjectそのものに変化を加えた。具体的にはUpdate内のif文をコメントアウトした。代わりにCanvas上にボタンを配置し、OnClickにPlaceObjectを登録した。また、ARマーカーから生成されなくなったためにVirtualRobotのスケールが変わったので、0.1→1にした。

 仮想ロボットが直進するようになった。また、一定以上障害物に近づいたら止まるようになった。

 現時点では2つ以上の障害物を避けることができない(1つ目しか認識しない)が、これは原因がわかっている。回避策として、一度回避したオブジェクトを消す方法を考案している。"実装としては仮想ロボットから-Z方向に一定以上離れたオブジェクトは削除する"と"障害物検知の際は`GameObject.FindGameObjectsWithtag`で障害物のリストを取得し、それぞれについて避ける動きを行う"という方向性で実現できそう



また、現在の避け方はUnityの世界でないとできないような動きになっているのでそれを現実的な動きに変更することが必要。一つ考えられるのは検知する距離を更に広くし、RCJの障害物回避のような動き(45°→前進→90°→前進→45°の動き)も案の一つであるが、障害物が密集しているとうまくいかないのでそれも考える必要がある。

### 2020年4月30日(MTGで頂いた意見)

+ SRAMについて勉強。
+ 現実の様子を見ながらマーカーを置いてルンバとかに対するプライベートな空間を明示出たら便利では
+ 床だけでなく壁も認識したいよね
+ ARだけでやる必要もなくて、部屋の空間データを手に入れることができればPC上でオブジェクトを配置して、それをロボットが解釈するようなものもいいよね
+ 発展性もありそうだから知識をつけたいところ
+ SLAMなどのキーワードで調べたり論文を読むようなことも大切
+ やっぱり知識入れないと…
+ あとROSでLiDARのシミュレーションも使えるといいよね(あまり聞き取れなかったのでakiraさんにもう一度聞きに行くといいかも)

### 2020年5月3日

 しばらく何も手をつけていなかった。